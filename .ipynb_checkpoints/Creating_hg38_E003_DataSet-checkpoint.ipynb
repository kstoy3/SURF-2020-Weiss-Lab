{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AwWEdAva_945"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#For data saving\n",
    "import pickle\n",
    "import random\n",
    "#other imports\n",
    "import gzip\n",
    "import glob\n",
    "import os\n",
    "import keras.backend as K\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "XiQbdXLRAWwz",
    "outputId": "a1321510-43e0-4212-f008-1b8a8be550c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59vW0oPKF4NF"
   },
   "outputs": [],
   "source": [
    "genome = ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLhQC-n3j6P0"
   },
   "source": [
    "**Data**:\n",
    "\n",
    "1. Getting the data and storing it on google drive (commented out)\n",
    "\n",
    "2. Retrieving data from google drive (all that is uncommented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y2NJVcpaj93j"
   },
   "outputs": [],
   "source": [
    "## Variable Declaration:\n",
    "chromosome = []\n",
    "start = [] # 0-based\n",
    "stop = [] # 1-based\n",
    "## For this model the label is 1 if it is an acitve enhancer and 0 otherwise\n",
    "label = [] #state_labelmnemonic\n",
    "count = 0\n",
    "\n",
    "## Going through file and getting the data\n",
    "with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_mnemonics.bed', 'rb') as f:\n",
    "    for line in f:\n",
    "        #L = line.decode().strip(\"\\t\")\n",
    "        L = line.decode().split(\"\\t\")\n",
    "        count += 1\n",
    "        chromosome.append(L[0])\n",
    "        start.append((L[1]))\n",
    "        stop.append((L[2]))\n",
    "        label.append(L[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yKRJLMjmmY39"
   },
   "outputs": [],
   "source": [
    "## Making sure code above worked:\n",
    "print(len(chromosome))\n",
    "print(len(start))\n",
    "print(len(stop))\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O37ZfOtG0eAb"
   },
   "source": [
    "##**Creating two sets of Data**\n",
    "##### 1. **Creating two categories:** \n",
    "  1 and 0: \n",
    "- 1 for '13_EnhA1\\n' \n",
    "- 0 for other types of elements\n",
    "\n",
    "##### 2. **Creating an array with markings for all 25 categories from chromHMM:** \n",
    "\n",
    "Another for all 25 categories split up by numbers without mnemonics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1kTb_KDzk06"
   },
   "outputs": [],
   "source": [
    "## Creating category changing labels to 13 or not:\n",
    "category_13_state = []\n",
    "for element in label:\n",
    "  if(element == '13_EnhA1\\n'):\n",
    "    category_13_state.append(1)\n",
    "  else:\n",
    "    category_13_state.append(0)\n",
    "print(len(category_13_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bVlhF7UKmw1q"
   },
   "outputs": [],
   "source": [
    "## Creating category changing labels to one of 25 states:\n",
    "category_25_states = []\n",
    "for element in label:\n",
    "  if(element[1] == '_'):\n",
    "    category_25_states.append(element[0])\n",
    "  else:\n",
    "    category_25_states.append(element[0:2])\n",
    "print(len(category_25_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tAha5q3unQXV"
   },
   "outputs": [],
   "source": [
    "#category_25_states[233424]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPWL25Kx0xTQ"
   },
   "source": [
    "**Retrieving Saved Data:**\n",
    "\n",
    "from gDrive\n",
    "\n",
    "Does not have the N's removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmwLVC4F01r9"
   },
   "outputs": [],
   "source": [
    "# Saving the arrays\n",
    "#with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_chromosome.dat', 'wb') as f:\n",
    "#  pickle.dump(chromosome, f)\n",
    "#with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_label.bed', 'wb') as f:\n",
    "#  pickle.dump(label, f)\n",
    "#with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_start.bed', 'wb') as f:\n",
    "#  pickle.dump(start, f)\n",
    "#with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_stop.bed', 'wb') as f:\n",
    "#  pickle.dump(stop, f)\n",
    "#with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_category_25_states.bed', 'wb') as f:\n",
    "#  pickle.dump(category_25_states, f)\n",
    "#with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_category_13_state.bed', 'wb') as f:\n",
    "#  pickle.dump(category_13_state, f)\n",
    "\n",
    "\n",
    "# Loading the arrays\n",
    "#with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_chromosome.dat', 'rb') as f:\n",
    "#  chromosome = pickle.load(f)\n",
    "#with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_label.bed', 'rb') as f:\n",
    "#  label = pickle.load(f)\n",
    "#with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_start.bed', 'rb') as f:\n",
    "#  start = pickle.load(f)\n",
    "#with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_stop.bed', 'rb') as f:\n",
    "#  stop = pickle.load(f)\n",
    "#with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_category_25_states.bed', 'rb') as f:\n",
    "#  category_25_states = pickle.load(f)\n",
    "#with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_category_13_state.bed', 'rb') as f:\n",
    "#  category_13_state = pickle.load(f)\n",
    "\n",
    "#print(len(chromosome))\n",
    "#print(len(label))\n",
    "#print(len(start))\n",
    "#print(len(stop))\n",
    "#print(len(category_25_states))\n",
    "#print(len(category_13_state))\n",
    "#print(chromosome[300])\n",
    "#print(label[300])\n",
    "#print(start[300])\n",
    "#print(stop[300])\n",
    "#print(category_25_states[300])\n",
    "#print(category_13_state[300]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2-F6qNW_Yiv"
   },
   "source": [
    "Saving the chromosomes into lists instead of fa files\n",
    "\n",
    "https://hgdownload.soe.ucsc.edu/goldenPath/hg38/chromosomes/ --> where I got sequence from, given by chromHMM prof. Jason Ernst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJx6h4si3ow0"
   },
   "outputs": [],
   "source": [
    "## Saving the chromosomes into arrays:\n",
    "\n",
    "##chromatin_files = []\n",
    "for chrom in range(0, len(genome)):\n",
    "  chr_array = []\n",
    "  with open('gdrive/My Drive/SURF_2020_Weiss/hg38/' + genome[chrom] + '.fa', 'r') as f:\n",
    "    while 1:\n",
    "      char = f.read(1)\n",
    "      if not char:\n",
    "        break\n",
    "      if char != ' ' and char != '\\n':\n",
    "        chr_array.append(char)\n",
    "  with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/' + genome[chrom] + '.dat', 'wb') as f:\n",
    "    pickle.dump(chr_array, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "we_7yNtKmEqe"
   },
   "outputs": [],
   "source": [
    "## Getting rid of the chr1 and other words before the sequence\n",
    "\n",
    "for chrom in range(0, len(genome)):\n",
    "  with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/' + genome[chrom] + '.dat', 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    #print(len(test))\n",
    "    #print(test[0][0:20])\n",
    "    with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/' + genome[chrom] + '_array.dat', 'wb') as f2:\n",
    "      new_array = []\n",
    "      if chrom < 9:\n",
    "        new_array.append(test[5:])\n",
    "      else:\n",
    "        new_array.append(test[6:])\n",
    "      pickle.dump(new_array, f2)\n",
    "    with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/' + genome[chrom] + '_array.dat', 'rb') as f3:\n",
    "      test_new = pickle.load(f3)\n",
    "      print(test_new[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHi_a6JE3pHx"
   },
   "source": [
    "**Extracting Sequences:** \n",
    "\n",
    "from chromosome files\n",
    "\n",
    "Going through hg19 DNA sequence and getting the sequences for each annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLMcttHB_-Oi"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i, chr in enumerate(genome):\n",
    "  with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/' + chr + '_array.dat', 'rb') as f1:\n",
    "    chromosome_array = pickle.load(f1)\n",
    "    seq = []\n",
    "    for j, chrom in enumerate(chromosome):\n",
    "      if chrom == chr:\n",
    "        seq.append(chromosome_array[0][int(start[j]): int(stop[j])])\n",
    "        count += 1\n",
    "    with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/' + chr + '_sequences.dat', 'wb') as f2:\n",
    "      pickle.dump(seq, f2)\n",
    "#print(count)\n",
    "#print(len(chromosome))\n",
    "#print(len(category_25_states))\n",
    "#print(len(category_13_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjOxTvPZPqjl"
   },
   "outputs": [],
   "source": [
    "#with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/' + 'chr1' + '_sequences.dat', 'rb') as f2:\n",
    "#  test = pickle.load(f2)\n",
    "#  print(len(test))\n",
    "#  print(test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nf8GLjkgQ_GQ"
   },
   "source": [
    "Getting rid of sequences that contain N (Not a valid DNA base pair):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gagLJA1ZRDcn"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "category_25_states_Nremoved = []\n",
    "category_13_state_Nremoved = []\n",
    "chromosome_Nremoved = []\n",
    "label_Nremoved = []\n",
    "for i, chr in enumerate(genome):\n",
    "  with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/' + chr + '_sequences.dat', 'rb') as f2:\n",
    "    chrom_array = pickle.load(f2)\n",
    "    sequences = []\n",
    "    for j in chrom_array:\n",
    "      if \"N\" not in j and 'n' not in j:\n",
    "        category_25_states_Nremoved.append(category_25_states[count])\n",
    "        category_13_state_Nremoved.append(category_13_state[count])\n",
    "        chromosome_Nremoved.append(chromosome[count])\n",
    "        label_Nremoved.append(label[count])\n",
    "        sequences.append(j)\n",
    "      count += 1\n",
    "    with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/' + chr + '_sequences_Nremoved.dat', 'wb') as f3:\n",
    "      pickle.dump(sequences, f3)\n",
    "      print(len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K_TZyuNFSA80"
   },
   "outputs": [],
   "source": [
    "## Checking if there was a change from removing N's\n",
    "#for i, chr in enumerate(genome):\n",
    "#  with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/' + chr + '_sequences.dat', 'rb') as f2:\n",
    "#    chrom_array = pickle.load(f2)\n",
    "#    print(len(chrom_array))\n",
    "#    with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/' + chr + '_sequences_Nremoved.dat', 'rb') as f3:\n",
    "#      chrom_array_2 = pickle.load(f3)\n",
    "#      print(len(chrom_array_2))\n",
    "#      if len(chrom_array) != len(chrom_array_2):\n",
    "#        print('yes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPbWDtjcSpwE"
   },
   "source": [
    "Code for opening and loading arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "pfdYlPtGSqJ6",
    "outputId": "01447181-0903-439c-d83d-446445db3c93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751466\n",
      "751466\n",
      "751466\n",
      "751466\n",
      "chr1\n",
      "1_TssA\n",
      "\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Saving the arrays\n",
    "#with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_chromosome_Nremoved.dat', 'wb') as f:\n",
    "#  pickle.dump(chromosome_Nremoved, f)\n",
    "#with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_label_Nremoved.bed', 'wb') as f:\n",
    "#  pickle.dump(label_Nremoved, f)\n",
    "#with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_category_25_states_Nremoved.bed', 'wb') as f:\n",
    "#  pickle.dump(category_25_states_Nremoved, f)\n",
    "#with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_category_13_state_Nremoved.bed', 'wb') as f:\n",
    "#  pickle.dump(category_13_state_Nremoved, f)\n",
    "\n",
    "\n",
    "# Loading the arrays\n",
    "with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_chromosome_Nremoved.dat', 'rb') as f:\n",
    "  chromosome = pickle.load(f)\n",
    "with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_label_Nremoved.bed', 'rb') as f:\n",
    "  label = pickle.load(f)\n",
    "with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_category_25_states_Nremoved.bed', 'rb') as f:\n",
    "  category_25_states = pickle.load(f)\n",
    "with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/E003_25_imputed12marks_category_13_state_Nremoved.bed', 'rb') as f:\n",
    "  category_13_state = pickle.load(f)\n",
    "\n",
    "print(len(chromosome))\n",
    "print(len(label))\n",
    "print(len(category_25_states))\n",
    "print(len(category_13_state))\n",
    "print(chromosome[300])\n",
    "print(label[300])\n",
    "print(category_25_states[300])\n",
    "print(category_13_state[300]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nySsjfaVTN-y"
   },
   "source": [
    "Preparing all seq for one hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wycyx5wCsHN"
   },
   "outputs": [],
   "source": [
    "def prep_for_onehot(chrom):\n",
    "  new_array = []\n",
    "  for seq in chrom:\n",
    "    seq_new = []\n",
    "    for nuc in seq:\n",
    "      if nuc == 'A' or nuc == 'a':\n",
    "        seq_new.append('a')\n",
    "      elif nuc == 'T' or nuc == 't':\n",
    "        seq_new.append('t')\n",
    "      elif nuc == 'G' or nuc == 'g':\n",
    "        seq_new.append('g')\n",
    "      elif nuc == 'C' or nuc == 'c':\n",
    "        seq_new.append('c')\n",
    "      else:\n",
    "        print(\"Found other codon\")\n",
    "        print(nuc)\n",
    "    new_array.append(seq_new)\n",
    "  return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 849
    },
    "id": "X4BDOtMKTSCa",
    "outputId": "3b9e7fda-81bb-4f01-f7eb-e4f8cde3c893"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66743\n",
      "66743\n",
      "57169\n",
      "57169\n",
      "47391\n",
      "47391\n",
      "37540\n",
      "37540\n",
      "39622\n",
      "39622\n",
      "42647\n",
      "42647\n",
      "40637\n",
      "40637\n",
      "33933\n",
      "33933\n",
      "34299\n",
      "34299\n",
      "35601\n",
      "35601\n",
      "37673\n",
      "37673\n",
      "37446\n",
      "37446\n",
      "20769\n",
      "20769\n",
      "24408\n",
      "24408\n",
      "24684\n",
      "24684\n",
      "24742\n",
      "24742\n",
      "31372\n",
      "31372\n",
      "17790\n",
      "17790\n",
      "27921\n",
      "27921\n",
      "19050\n",
      "19050\n",
      "8969\n",
      "8969\n",
      "14633\n",
      "14633\n",
      "26425\n",
      "26425\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i, chr in enumerate(genome):\n",
    "  with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/' + chr + '_sequences_Nremoved.dat', 'rb') as f2:\n",
    "    chrom_array = pickle.load(f2)\n",
    "    sequences = prep_for_onehot(chrom_array)\n",
    "    print(len(chrom_array))\n",
    "    with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/' + chr + '_sequences_onehotpreped.dat', 'wb') as f3:\n",
    "      pickle.dump(sequences, f3)\n",
    "      print(len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "8_XUW6IAU-r3",
    "outputId": "e2db72f3-88e5-401b-9935-4e60e6da3291"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 66743, 123912, 171303, 208843, 248465, 291112, 331749, 365682, 399981, 435582, 473255, 510701, 531470, 555878, 580562, 605304, 636676, 654466, 682387, 701437, 710406, 725039, 751464, 751466]\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "## Creating Genome indexes:\n",
    "hg38_indexes = []\n",
    "hg38_indexes.append(0)\n",
    "num = 0 \n",
    "for i, chr in enumerate(genome):\n",
    "  with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/' + chr + '_sequences_onehotpreped.dat', 'rb') as f3:\n",
    "    chrom_array = pickle.load(f3)\n",
    "    num += len(chrom_array)\n",
    "    hg38_indexes.append(num)\n",
    "print(hg38_indexes)\n",
    "print(len(hg38_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CqBE5uvhVfba"
   },
   "outputs": [],
   "source": [
    "#with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/hg38_indexes.dat', 'wb') as f3:\n",
    "#  pickle.dump(hg38_indexes, f3)\n",
    "with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/hg38_indexes.dat', 'rb') as f3:\n",
    "  hg38_indexes = pickle.load(f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSO4-Mf6-3v_"
   },
   "source": [
    "**Creating the reverse of each DNA sequence:**\n",
    "\n",
    "*   This is done to take into account the complementary strand and to keep the machine learning model from focusing too much on directional patterns\n",
    "*   Either of the strands could be causing epigenomic modification, so we include them both\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSUeTfWb_Zaa"
   },
   "outputs": [],
   "source": [
    "def get_reverse(chrom):\n",
    "  reverse_chrom_array = []\n",
    "  for seq in chrom:\n",
    "    rev = seq[::-1]\n",
    "    reverse_chrom_array.append(rev)\n",
    "  return reverse_chrom_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "-BYoLAJg_Ho4",
    "outputId": "d98ebf04-4ed2-4405-8748-a321dc945d18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['c', 'c', 't', 't', 'a'], ['a'], ['c', 't', 'g', 't', 't', 'a'], ['t', 'c', 'g', 't'], ['c', 't', 'g', 'a']]\n"
     ]
    }
   ],
   "source": [
    "test = [['a', 't', 't', 'c','c'],['a'],['a', 't', 't', 'g', 't', 'c'],['t', 'g', 'c', 't'],['a', 'g', 't', 'c']]\n",
    "print(get_reverse(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4uEj-oyz_AKP"
   },
   "outputs": [],
   "source": [
    "## Creating a file for each chromosome with the reverse\n",
    "for i, chr in enumerate(genome):\n",
    "  reverse_chrom_array = []\n",
    "  with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/' + chr + '_sequences_onehotpreped.dat', 'rb') as f1:\n",
    "    chrom_array = pickle.load(f1)\n",
    "    with open('gdrive/My Drive/SURF_2020_Weiss/E003_hg38_25_imputed12marks/' + chr + '_sequences_onehotpreped_reversed.dat', 'wb') as f2:\n",
    "      reverse_chrom_array = get_reverse(chrom_array)\n",
    "      pickle.dump(reverse_chrom_array, f2)\n",
    "    if len(chrom_array) != len(reverse_chrom_array) or len(chrom_array[1]) != len(reverse_chrom_array[1]):\n",
    "      print('Not proper reverse')\n",
    "      break"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Creating hg38_E003_DataSet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
