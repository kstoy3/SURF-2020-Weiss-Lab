{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#For data saving\n",
    "import pickle\n",
    "import random\n",
    "#other imports\n",
    "import os\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Lab-of-origins\n",
    "def convert_onehot2D(list_of_seqs):\n",
    "    list_of_onehot2D_seqs = np.zeros((len(list_of_seqs),4,len(list_of_seqs[0])))\n",
    "    nt_dict = {'A':[1,0,0,0],'T':[0,1,0,0],'G':[0,0,1,0],'C':[0,0,0,1], 'N':[0,0,0,0]}\n",
    "    count = 0\n",
    "    for seq in list_of_seqs:\n",
    "        if len(seq) > 1:\n",
    "            for letter in range(len(seq)):\n",
    "                for i in range(4):\n",
    "                    list_of_onehot2D_seqs[count][i][letter] = (nt_dict[seq[letter]])[i]\n",
    "        count += 1\n",
    "    return list_of_onehot2D_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Lab-of-origins\n",
    "def pad_dna(seqs,maxlen):\n",
    "    start = time.time()\n",
    "    padded_seqs = [''] * len(seqs)\n",
    "    for i in seqs:\n",
    "        if len(i) > maxlen:\n",
    "            i = i[:maxlen]\n",
    "            maxlen = len(i)\n",
    "    for j in range(len(seqs)):\n",
    "        if len(seqs[j]) > maxlen:\n",
    "            seq = seqs[j][0:maxlen]\n",
    "        else:\n",
    "            seq = seqs[j]\n",
    "        padded_seqs[j] = seq + \"N\" * (maxlen - len(seq))\n",
    "    end = time.time()\n",
    "    return padded_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Lab-of-origins\n",
    "def convert_seq_to_atgcn(seq):\n",
    "    char_list = list(string.printable)\n",
    "    for i in ['A','T','G','C','a','t','g','c']:\n",
    "        char_list.remove(i)\n",
    "    for ch in char_list:\n",
    "        if ch in seq:\n",
    "            seq=seq.replace(ch,\"N\")\n",
    "    return seq.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_rc(seqs,filter_length):\n",
    "    start = time.time()\n",
    "    full_seqs = [''] * len(seqs)\n",
    "    rc_dict = {'A':'T','T':'A','G':'C','C':'G','N':'N'}\n",
    "    for j in range(len(seqs)):\n",
    "        fwd_seq = seqs[j]\n",
    "        complement_seq = ''\n",
    "        for n in fwd_seq:\n",
    "            complement_seq += rc_dict[n]\n",
    "        full_seqs[j] = fwd_seq + 'N'*filter_length + complement_seq[::-1] #[::-1] reverses string \n",
    "    end = time.time()\n",
    "    return full_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(len(train_samples))\\nfor ID in train_samples:\\n    if labels[ID][0][0] == 0:\\n        train_samples.remove(ID)\\nprint(len(train_samples))\\nprint(labels[train_samples[0]])\\n\\nprint(len(val_samples))\\nfor ID in val_samples:\\n    if labels[ID][0][0] == 0:\\n        val_samples.remove(ID)\\nprint(len(val_samples))\\nprint(labels[val_samples[0]])\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../partition_train_val_a.dat', 'rb') as f:\n",
    "    partition = pickle.load(f)\n",
    "train_samples = partition['train']\n",
    "val_samples = partition['validation']\n",
    "random.shuffle(train_samples)\n",
    "random.shuffle(val_samples)\n",
    "labels = partition['labels']\n",
    "partition['train'] = train_samples\n",
    "partition['validation'] = val_samples\n",
    "'''\n",
    "print(len(train_samples))\n",
    "for ID in train_samples:\n",
    "    if labels[ID][0][0] == 0:\n",
    "        train_samples.remove(ID)\n",
    "print(len(train_samples))\n",
    "print(labels[train_samples[0]])\n",
    "\n",
    "print(len(val_samples))\n",
    "for ID in val_samples:\n",
    "    if labels[ID][0][0] == 0:\n",
    "        val_samples.remove(ID)\n",
    "print(len(val_samples))\n",
    "print(labels[val_samples[0]])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, val_samples = remove_zero_category()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.zeros((200, 2), dtype=np.int8)\n",
    "X_train = np.zeros((200, 1000, 4), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16382\n"
     ]
    }
   ],
   "source": [
    "with open('../partition_test_a.dat', 'rb') as f:\n",
    "    partition = pickle.load(f)\n",
    "test_samples_IDs = partition['test']\n",
    "\n",
    "with open('../test_labels.dat', 'rb') as f:\n",
    "    test_labels = pickle.load(f)\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "count_input_train = 0\n",
    "a = train_samples[count_input_train]\n",
    "X_train[0, :, :] = np.load('../model_11_data_4/' + train_samples[count_input_train] + '.npy') \n",
    "Y_train[0, :] = labels[a] \n",
    "print(Y_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "count_input_train = 0\n",
    "count_input_validation = 0\n",
    "while count_input_train < len(train_samples):\n",
    "    Y_train = np.zeros((200, 2), dtype=np.int8)\n",
    "    X_train = np.zeros((200, 1000, 4), dtype=np.int8)\n",
    "    Y_val = np.zeros((40, 2), dtype=np.int8)\n",
    "    X_val = np.zeros((40, 1000, 4), dtype=np.int8)\n",
    "    if count_input_train < (len(train_samples) - 200):\n",
    "        for i in range(0, 200):\n",
    "            a = train_samples[count_input_train]\n",
    "            X_train[i, :, :] = np.load('../model_11_data_4/' + train_samples[count_input_train] + '.npy') \n",
    "            Y_train[i, :] = labels[a] \n",
    "            count_input_train += 1\n",
    "            if count_input_train < 2:\n",
    "                for j in range(1, 2):\n",
    "                    print(X_train[j][300:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "7632\n",
      "8568\n"
     ]
    }
   ],
   "source": [
    "expected = []\n",
    "count_1 = 0\n",
    "count_0 = 0\n",
    "\n",
    "for label in test_labels[0:16200]:\n",
    "    expected.append(label[0][0])\n",
    "    if label[0][0] == 1:\n",
    "        count_1 += 1\n",
    "    elif label[0][0] == 0:\n",
    "        count_0 += 1\n",
    "    else:\n",
    "        print(label[0][0])\n",
    "        \n",
    "print(expected[0])\n",
    "print(count_1)\n",
    "print(count_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
