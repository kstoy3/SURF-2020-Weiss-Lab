{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SoFyIizw-YaT"
   },
   "source": [
    "CNN LSTM \n",
    "\n",
    "Data Set 14\n",
    "Using data zero data zero padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ISksYe7Fr3LI"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input ,Dense, Dropout, Activation, LSTM, Conv1D\n",
    "from keras.layers import Lambda, Convolution1D, MaxPooling1D, Flatten, Reshape, BatchNormalization\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras.metrics import categorical_crossentropy, binary_crossentropy\n",
    "\n",
    "#from spp.SpatialPyramidPooling import SpatialPyramidPooling\n",
    "\n",
    "#For data saving\n",
    "import pickle\n",
    "import random\n",
    "#other imports\n",
    "import gzip\n",
    "import glob\n",
    "import os\n",
    "import keras.backend as K\n",
    "import os\n",
    "import time \n",
    "#cwd = os.path.dirname(os.path.realpath(\"SURF_001_TwoClass13.ipynb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MVqz_9kQi7bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5AyunGGYTSd"
   },
   "outputs": [],
   "source": [
    "genome = ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zbM8m6yq2ZIX"
   },
   "source": [
    "**Creating Dataframe**\n",
    "\n",
    "https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(1000, 4), n_channels=0,\n",
    "                 n_classes=2, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, 1000, 4))\n",
    "        y = np.empty((self.batch_size, self.n_classes), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = np.load('../model_11_data_4/' + ID + '.npy')\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-06FGqcExs6j"
   },
   "outputs": [],
   "source": [
    "dense_layer = 1\n",
    "layer_size = 64 \n",
    "conv_layer = 2\n",
    "seq_length = 1000\n",
    "base_pair = 4\n",
    "num_strides = 1\n",
    "pool_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_count = 0\n",
    "with open('../partition_train_val_a.dat', 'rb') as f:\n",
    "    partition = pickle.load(f)\n",
    "for index in partition['train']:\n",
    "    a = partition['labels'][index][0][0]\n",
    "    if test_count < 10:\n",
    "        print(a)\n",
    "    partition['labels'][index] = a\n",
    "    test_count += 1\n",
    "    if test_count < 10:\n",
    "        print(partition['labels'][index])\n",
    "for index in partition['validation']:\n",
    "    a = partition['labels'][index][0][0]\n",
    "    partition['labels'][index] = a\n",
    "    test_count += 1\n",
    "    if test_count < 20:\n",
    "        print(partition['labels'][index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_1 = 0\n",
    "cat_0 = 0\n",
    "for i in partition['train']:\n",
    "    if partition['labels'][i] == 0:\n",
    "        cat_0 += 1\n",
    "    elif partition['labels'][i] == 1:\n",
    "        cat_1 += 1\n",
    "    else:\n",
    "        print('issue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat_1)\n",
    "print(cat_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'dim': (32,1000,4),\n",
    "          'batch_size': 64,\n",
    "          'n_classes': 2,\n",
    "          'n_channels': 1,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Datasets\n",
    "#with open('../partition_train_val_a.dat', 'rb') as f:\n",
    "   # partition = pickle.load(f)\n",
    "\n",
    "labels = partition['labels']\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(partition['train'], labels, **params)\n",
    "validation_generator = DataGenerator(partition['validation'], labels, **params)\n",
    "\n",
    "# Design model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=layer_size, kernel_size=(4), input_shape=(seq_length, 4), activation='relu', strides=1, padding='valid'))\n",
    "model.add(Conv1D(layer_size, 4, batch_input_shape=(32, seq_length, 4), strides=1, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4, strides=None, padding='valid', data_format='channels_last'))\n",
    "model.add(Dropout(0.1, noise_shape=None, seed=None))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(12))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# Train model on dataset\n",
    "model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54082\n",
      "35258\n",
      "[[1 0]]\n",
      "13520\n",
      "8792\n",
      "[[1 0]]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 997, 64)           1088      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 249, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 246, 64)           16448     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 61, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 61, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 58, 64)            16448     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 14, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 11, 64)            16448     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 543,874\n",
      "Trainable params: 543,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\kriss\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\kriss\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ../Models_H5/011_1-conv-64-nodes-1-dense-1601502731CNNLSTM\\assets\n",
      "Epoch 1/500\n",
      "7/7 - 2s - loss: 0.6488 - accuracy: 0.6300 - val_loss: 0.5440 - val_accuracy: 0.7250\n",
      "Epoch 2/500\n",
      "7/7 - 0s - loss: 0.6034 - accuracy: 0.6900 - val_loss: 0.5576 - val_accuracy: 0.7250\n",
      "Epoch 3/500\n",
      "7/7 - 0s - loss: 0.5984 - accuracy: 0.6900 - val_loss: 0.5363 - val_accuracy: 0.7250\n",
      "Epoch 4/500\n",
      "7/7 - 0s - loss: 0.5867 - accuracy: 0.6900 - val_loss: 0.5324 - val_accuracy: 0.7250\n",
      "Epoch 5/500\n",
      "7/7 - 0s - loss: 0.5797 - accuracy: 0.6900 - val_loss: 0.5208 - val_accuracy: 0.7250\n",
      "Epoch 6/500\n",
      "7/7 - 0s - loss: 0.5868 - accuracy: 0.7250 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
      "Epoch 7/500\n",
      "7/7 - 0s - loss: 0.5735 - accuracy: 0.7350 - val_loss: 0.5117 - val_accuracy: 0.8250\n",
      "Epoch 8/500\n",
      "7/7 - 0s - loss: 0.5652 - accuracy: 0.7600 - val_loss: 0.4975 - val_accuracy: 0.8250\n",
      "Epoch 9/500\n",
      "7/7 - 0s - loss: 0.5591 - accuracy: 0.7600 - val_loss: 0.4898 - val_accuracy: 0.8250\n",
      "Epoch 10/500\n",
      "7/7 - 0s - loss: 0.5499 - accuracy: 0.7600 - val_loss: 0.4959 - val_accuracy: 0.8250\n",
      "Epoch 11/500\n",
      "7/7 - 0s - loss: 0.5527 - accuracy: 0.7600 - val_loss: 0.4965 - val_accuracy: 0.8250\n",
      "Epoch 12/500\n",
      "7/7 - 0s - loss: 0.6000 - accuracy: 0.7200 - val_loss: 0.5140 - val_accuracy: 0.8250\n",
      "Epoch 13/500\n",
      "7/7 - 0s - loss: 0.6166 - accuracy: 0.7550 - val_loss: 0.5756 - val_accuracy: 0.8250\n",
      "Epoch 14/500\n",
      "7/7 - 0s - loss: 0.5979 - accuracy: 0.6850 - val_loss: 0.5342 - val_accuracy: 0.7250\n",
      "Epoch 15/500\n",
      "7/7 - 0s - loss: 0.5779 - accuracy: 0.6900 - val_loss: 0.5419 - val_accuracy: 0.7250\n",
      "Epoch 16/500\n",
      "7/7 - 0s - loss: 0.5758 - accuracy: 0.6900 - val_loss: 0.5355 - val_accuracy: 0.7250\n",
      "Epoch 17/500\n",
      "7/7 - 0s - loss: 0.5692 - accuracy: 0.6900 - val_loss: 0.5133 - val_accuracy: 0.7250\n",
      "Epoch 18/500\n",
      "7/7 - 0s - loss: 0.5541 - accuracy: 0.7650 - val_loss: 0.4844 - val_accuracy: 0.8250\n",
      "Epoch 19/500\n",
      "7/7 - 0s - loss: 0.5412 - accuracy: 0.7600 - val_loss: 0.4641 - val_accuracy: 0.8250\n",
      "Epoch 20/500\n",
      "7/7 - 0s - loss: 0.5308 - accuracy: 0.7600 - val_loss: 0.4793 - val_accuracy: 0.8250\n",
      "Epoch 21/500\n",
      "7/7 - 0s - loss: 0.5354 - accuracy: 0.7600 - val_loss: 0.4799 - val_accuracy: 0.8250\n",
      "Epoch 22/500\n",
      "7/7 - 0s - loss: 0.5104 - accuracy: 0.7650 - val_loss: 0.4631 - val_accuracy: 0.8250\n",
      "Epoch 23/500\n"
     ]
    }
   ],
   "source": [
    "with open('../partition_train_val_a.dat', 'rb') as f:\n",
    "    partition = pickle.load(f)\n",
    "train_samples = partition['train']\n",
    "val_samples = partition['validation']\n",
    "random.shuffle(train_samples)\n",
    "random.shuffle(val_samples)\n",
    "\n",
    "labels = partition['labels']\n",
    "partition['train'] = train_samples\n",
    "partition['validation'] = val_samples\n",
    "\n",
    "print(len(train_samples))\n",
    "for ID in train_samples:\n",
    "    if labels[ID][0][0] == 0:\n",
    "        train_samples.remove(ID)\n",
    "print(len(train_samples))\n",
    "print(labels[train_samples[0]])\n",
    "\n",
    "print(len(val_samples))\n",
    "for ID in val_samples:\n",
    "    if labels[ID][0][0] == 0:\n",
    "        val_samples.remove(ID)\n",
    "print(len(val_samples))\n",
    "print(labels[val_samples[0]])\n",
    "\n",
    "\n",
    "'''\n",
    "a = partition['train'][0]\n",
    "print(a)\n",
    "print(partition['labels'][a] )\n",
    "train_labels = np.empty(1, dtype=np.int8)\n",
    "train_samples = []\n",
    "train_labels[0] = partition['labels'][a] \n",
    "train_samples = np.load('../model_11_data_4/' + partition['train'][0] + '.npy')\n",
    "\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(train_samples.shape)\n",
    "\n",
    "\n",
    "val_labels = train_labels\n",
    "val_samples = train_samples\n",
    "print(val_labels.shape)\n",
    "print(val_samples.shape)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "params = {'dim': (32,1000,4),\n",
    "          'batch_size': 64,\n",
    "          'n_classes': 2,\n",
    "          'n_channels': 1,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Datasets\n",
    "#with open('../partition_train_val_a.dat', 'rb') as f:\n",
    "   # partition = pickle.load(f)\n",
    "\n",
    "\n",
    "# Generators\n",
    "#training_generator = DataGenerator(partition['train'], labels, **params)\n",
    "#validation_generator = DataGenerator(partition['validation'], labels, **params)\n",
    "\n",
    "dense_layers = [1]\n",
    "layer_sizes = [64]\n",
    "conv_layers = [1]\n",
    "\n",
    "# Design model\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            Earlystop = EarlyStopping(\n",
    "            monitor='val_loss', min_delta=0, patience=25, verbose=0, mode='auto',\n",
    "            baseline=None, restore_best_weights=True)\n",
    "            count_input_train = 0\n",
    "            count_input_validation = 0\n",
    "            while count_input_train < len(partition['train']):\n",
    "                Y_train = np.zeros((200, 2), dtype=np.int8)\n",
    "                X_train = np.zeros((200, 1000, 4), dtype=np.int8)\n",
    "                Y_val = np.zeros((40, 2), dtype=np.int8)\n",
    "                X_val = np.zeros((40, 1000, 4), dtype=np.int8)\n",
    "                if count_input_train < (len(train_samples) - 200):\n",
    "                    for i in range(0, 200):\n",
    "                        a = train_samples[count_input_train]\n",
    "                        X_train[i, :, :] = np.load('../model_11_data_4/' + train_samples[count_input_train] + '.npy') \n",
    "                        Y_train[i, :] = partition['labels'][a] \n",
    "                        count_input_train += 1\n",
    "                else:\n",
    "                    count_input_train += 1000\n",
    "                if count_input_validation < (len(partition['validation']) - 40):\n",
    "                    for i in range(0, 40):\n",
    "                        a = partition['validation'][count_input_validation]\n",
    "                        X_val[i, :, :] = np.load('../model_11_data_4/' + partition['validation'][count_input_validation] + '.npy') \n",
    "                        Y_val[i, :] = partition['labels'][a] \n",
    "                        count_input_validation += 1\n",
    "\n",
    "                model = Sequential()\n",
    "                model.add(Conv1D(filters=layer_size, kernel_size=(4), input_shape=(seq_length, 4), activation='relu', strides=1, padding='valid'))\n",
    "                model.add(MaxPooling1D(pool_size=4, strides=None, padding='valid', data_format='channels_last'))\n",
    "                model.add(Conv1D(layer_size, 4, batch_input_shape=(1, seq_length, 4), strides=1, padding='valid', activation='relu'))\n",
    "                model.add(MaxPooling1D(pool_size=4, strides=None, padding='valid', data_format='channels_last'))\n",
    "\n",
    "                model.add(Dropout(0.01, noise_shape=None, seed=None))\n",
    "                model.add(Conv1D(layer_size, 4, batch_input_shape=(1, seq_length, 4), strides=1, padding='valid', activation='relu'))\n",
    "                model.add(MaxPooling1D(pool_size=4, strides=None, padding='valid', data_format='channels_last'))\n",
    "\n",
    "                model.add(Dropout(0.01, noise_shape=None, seed=None))\n",
    "                model.add(Conv1D(layer_size, 4, batch_input_shape=(1, seq_length, 4), strides=1, padding='valid', activation='relu'))\n",
    "                model.add(MaxPooling1D(pool_size=4, strides=None, padding='valid', data_format='channels_last'))\n",
    "\n",
    "                model.add(Dropout(0.01, noise_shape=None, seed=None))\n",
    "\n",
    "                for l in range(conv_layer-1):\n",
    "                    model.add(MaxPooling1D(pool_size=4, strides=None, padding='valid', data_format='channels_last'))\n",
    "                    model.add(Conv1D(layer_size, 4, activation='relu'))\n",
    "\n",
    "                #model.add(MaxPooling1D(pool_size=2, strides=None, padding='valid', data_format='channels_last'))\n",
    "                #model.add(Conv1D(64, 4, activation='relu'))\n",
    "\n",
    "                model.add(Dropout(0.1, noise_shape=None, seed=None))\n",
    "\n",
    "                model.add(LSTM(128))\n",
    "\n",
    "                model.add(Flatten())\n",
    "                \n",
    "                model.add(Dense(512))\n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(Dropout(0.01))\n",
    "                model.add(Dense(512))\n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(Dropout(0.01))\n",
    "\n",
    "                for l in range(dense_layer):\n",
    "                    model.add(Dense(128))\n",
    "                    model.add(Activation('relu'))\n",
    "                model.add(Dense(2, activation='softmax'))\n",
    "                \n",
    "                opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "               # optimizer = keras.optimizers.Adam(lr=0.00001)\n",
    "                model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                if count_input_train < 400:\n",
    "                    print(model.summary())\n",
    "                    model.save('../Models_H5/011_{}-conv-{}-nodes-{}-dense-{}CNNLSTM'.format(conv_layer, layer_size, dense_layer, int(time.time())))\n",
    "                                # Train model on dataset\n",
    "                model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=500, callbacks=[Earlystop], verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFLDeml38Fff"
   },
   "outputs": [],
   "source": [
    "#Testing which model I'll pick\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vLBMGfufTtBE"
   },
   "outputs": [],
   "source": [
    "with open('../partition_train_val_a.dat', 'rb') as f:\n",
    "    partition = pickle.load(f)\n",
    "train_samples_IDs = partition['train']\n",
    "val_samples_IDs = partition['validation']\n",
    "IDs = partition['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../Models_H5/011_{}-conv-{}-nodes-{}-dense-{}CNNLSTM'.format(1, 128, 1, 1601188309))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zPfOnM6TT1yl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n",
      "3200\n",
      "3400\n",
      "3600\n",
      "3800\n",
      "4000\n",
      "4200\n",
      "4400\n",
      "4600\n",
      "4800\n",
      "5000\n",
      "5200\n",
      "5400\n",
      "5600\n",
      "5800\n",
      "6000\n",
      "6200\n",
      "6400\n",
      "6600\n",
      "6800\n",
      "7000\n",
      "7200\n",
      "7400\n",
      "7600\n",
      "7800\n",
      "8000\n",
      "8200\n",
      "8400\n",
      "8600\n",
      "8800\n",
      "9000\n",
      "9200\n",
      "9400\n",
      "9600\n",
      "9800\n",
      "10000\n",
      "10200\n",
      "10400\n",
      "10600\n",
      "10800\n",
      "11000\n",
      "11200\n",
      "11400\n",
      "11600\n",
      "11800\n",
      "12000\n",
      "12200\n",
      "12400\n",
      "12600\n",
      "12800\n",
      "13000\n",
      "13200\n",
      "13400\n",
      "13400\n",
      "13400\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "Y_val_expected = []\n",
    "count_input_val = 0\n",
    "num_val_seq = len(partition['validation'])\n",
    "done = False\n",
    "while count_input_val < num_val_seq and not(done):\n",
    "    X_val = np.zeros((200, 1000, 4), dtype=np.int8)\n",
    "    if count_input_val < (num_val_seq - 200):\n",
    "        for i in range(0, 200):\n",
    "            a = partition['validation'][count_input_val]\n",
    "            X_val[i, :, :] = np.load('../model_11_data_4/' + partition['validation'][count_input_val] + '.npy') \n",
    "            count_input_val += 1\n",
    "        predict = (model.predict_classes(X_val))\n",
    "        for label in predict:\n",
    "            predicted.append(label)\n",
    "    else:\n",
    "        done = True\n",
    "    if count_input_val == 16200:\n",
    "        done = True\n",
    "    print(count_input_val)\n",
    "print(len(predicted))\n",
    "print(predicted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "13520\n"
     ]
    }
   ],
   "source": [
    "expected = []\n",
    "\n",
    "for label in val_samples_IDs:\n",
    "    expected.append(IDs[label][0][0])\n",
    "print(expected[0])\n",
    "print(len(expected))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1779 5420]\n",
      " [1498 4703]]\n"
     ]
    }
   ],
   "source": [
    "# Example of a confusion matrix in Python\n",
    "from sklearn.metrics import confusion_matrix\n",
    " \n",
    "results = confusion_matrix(expected[0:13400], predicted)\n",
    "print(results)\n",
    "# Printing the precision and recall, among other metrics\n",
    "#print(metrics.classification_report(y_act, y_pred, labels=[\"a\", \n",
    "#\"b\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Model.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x0000019CB7867040>>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(results/np.sum(results), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "print(model.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HERE 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fwAOFewy7-2X"
   },
   "source": [
    "Extra Code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vLBMGfufTtBE"
   },
   "outputs": [],
   "source": [
    "with open('../partition_test_a.dat', 'rb') as f:\n",
    "    partition = pickle.load(f)\n",
    "test_samples_IDs = partition['test']\n",
    "\n",
    "with open('../test_labels.dat', 'rb') as f:\n",
    "    test_labels = pickle.load(f)\n",
    "print(len(test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../Models_H5/SURF_Paper_9.26.20/011_{}-conv-{}-nodes-{}-dense-{}CNNLSTM-9-26-20'.format(1, 64, 0, 1601093561))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zPfOnM6TT1yl"
   },
   "outputs": [],
   "source": [
    "predicted = []\n",
    "count_input_test = 0\n",
    "num_test_seq = len(partition['test'])\n",
    "done = False\n",
    "while count_input_test < num_test_seq and not(done):\n",
    "    X_test = np.zeros((200, 1000, 4), dtype=np.int8)\n",
    "    if count_input_test < (num_test_seq - 200):\n",
    "        for i in range(0, 200):\n",
    "            a = partition['test'][count_input_test]\n",
    "            X_test[i, :, :] = np.load('../DataSet_14_Test_2/' + partition['test'][count_input_test] + '.npy') \n",
    "            count_input_test += 1\n",
    "        predict = (model.predict_classes(X_test))\n",
    "        for label in predict:\n",
    "            predicted.append(label)\n",
    "    else:\n",
    "        done = True\n",
    "    if count_input_test == 16200:\n",
    "        done = True\n",
    "    print(count_input_test)\n",
    "print(len(predicted))\n",
    "print(len(test_labels))\n",
    "print(predicted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = []\n",
    "for label in test_labels[0:16200]:\n",
    "    expected.append(label[0][0])\n",
    "print(expected[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a confusion matrix in Python\n",
    "from sklearn.metrics import confusion_matrix\n",
    " \n",
    "results = confusion_matrix(expected, predicted)\n",
    "print(results)\n",
    "# Printing the precision and recall, among other metrics\n",
    "#print(metrics.classification_report(y_act, y_pred, labels=[\"a\", \n",
    "#\"b\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(results/np.sum(results), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('loss')<0.4):\n",
    "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images/255.0\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "011_E003_CNN_DataSet13_2categories_.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
